---
description: Docs intro
layout: ../../../layouts/MainLayout.astro
---

# 多任务——线程

## 什么是多任务

有很多的场景中的事情是**同时进行**的，比如开车的时候手和脚共同来驾驶汽车，再比如唱歌跳舞同时进行：

我们尝试编写一个程序，来模拟“唱歌跳舞”这件事情：

```python
from time import sleep

def sing():
    for i in range(3):
        print("正在唱歌...%d" % i)
        sleep(1)	# 停止1秒钟

def dance():
    for i in range(3):
        print("正在跳舞...%d" % i)
        sleep(1)	# 停止1秒钟

if __name__ == '__main__':
    sing()  	# 唱歌
    dance()  	# 跳舞
```

+ 刚刚的程序还是按照定函数调用的顺序执行，并没有完成唱歌和跳舞同时进行的要求

+ 如果想要实现“唱歌跳舞”同时进行，那么就需要一个新的方法，叫做：**多任务**

多任务，简单地说，就是操作系统可以同时运行多个任务。

打个比方，你一边在用浏览器上网，一边在听MP3，一边在用Word写报告，这就是多任务，这样就至少同时有3个任务正在运行。还有很多任务悄悄地在后台同时运行着，只是桌面上没有显示而已。 

加入了多任务的程序，执行速度会大大提升。

### 并行与并发

现在，多核CPU已经非常普及了，但是，即使过去的单核CPU，也可以执行多任务。由于CPU执行代码都是**顺序执行**的，那么，单核CPU是怎么执行多任务的呢？ 答案就是操作系统轮流让**各个任务交替执行**，任务1执行0.01秒，切换到任务2，任务2执行0.01秒，再切换到任务3，执行0.01秒……这样反复执行下去。

表面上看，每个任务都是交替执行的，但是，由于CPU的执行速度实在是太快了，我们感觉就像所有任务都在同时执行一样。 **真正的并行执行多任务只能在多核CPU上实现**，但是，由于任务数量远远多于CPU的核心数量，所以，操作系统也会自动把很多任务轮流调度到每个核心上执行。 

于是，并行和并发的概念如下：

+ 并发：指的是任务数多于CPU核数，通过操作系统的各种任务调度算法，实现用多个任务“一起”执行（实际上总有一些任务不在执行，因为**切换任务的速度相当快**，看上去一起执行而已 ） ；

+ 并行：指的是任务数小于等于CPU核数，即任务**真的是一起执行**的。

在Python中，多任务是基于**并发**完成的。

## 线程的概念

**线程**，是程序执行的最小单位（资源调度的最小单位 ）。只占用一条线程的程序我们称之为**单线程程序**，占用多条线程的程序我们称为**多线程程序**。

Python脚本每次执行时都将启用一条**主线程**，若还要添加执行不同功能的线程，需要引入一些内置模块。

`thread`内置模块可以在Python脚本中编辑线程（可将单线程程序变为多线程程序 ）。然而`thread`较为底层（在Python3中已被废弃，改为`_thread`模块 ），Python的另一个`threading`模块对`thread`做了一些功能上的封装，可以更加方便的被使用。我们在这里主要介绍`threading`模块的用法。

## threading 模块

### 线程的创建与运行

我们可以通过以下方式，定义一个执行特定函数或方法的线程：

```python
import threading
t = threading.Thread(target=函数/方法名, args=(参数))		
```

`t`即为定义的线程，传入函数名和参数两个关键字形参，若无参数，`args`可省略；有参数时`args`以**元组**形式传入（注意参数仅一个元素时，参数后面要加逗号 ）。

线程定义后，要调用其`start()`方法才能使其运行：

```python
t.start()	# 启动线程
```

程序中创建的这些线程，不同于主线程，我们称之为**子线程**。当所有子线程都执行完毕后，主线程才会结束。即使主线程执行到最后一句，它也会等待所有子线程执行完毕后再结束。拿唱歌跳舞的程序举个例子：

```python
from time import sleep
import threading

def sing(n):
    for i in range(n):
        print("正在唱歌...%d" % i)
        sleep(1)	# 停止1秒钟

def dance():
    for i in range(3):
        print("正在跳舞...%d" % i)
        sleep(1)	# 停止1秒钟

if __name__ == '__main__':
    threading.Thread(target=sing, args=(3, )).start()	# 传参创建一个线程并启动
    threading.Thread(target=dance).start()	# 创建一个线程并启动
    print('这是主线程的最后一句')
```

从执行结果可以看出，两个方法已经能够交错执行了，即实现了多线程并发。执行完主线程后，程序继续执行子线程的方法，直至结束。

若想要一个线程执行结束后，再继续执行后面的代码，可以使用`join`方法。

例如：开10个线程，分别计算1至1e7的和，最后计算程序总共所需的时间：

```python
import time
from threading import Thread

def func():
    sum = 0
    for i in range(1, int(1e7 + 1)):
        sum += i
    print(sum)

if __name__ == '__main__':
    start_time = time.time()
    # 创建线程列表
    t = []
    for i in range(0, 10):
        thread = Thread(target=func)
        t.append(thread)	# 将线程加入列表
        thread.start()	# 开启线程
    for i in t:	# t列表中保存了所有线程，每个线程都调用join()方法所有线程执行完毕后才能计算时间
        i.join()				
    print("程序用时%f秒" % (time.time() - start_time))
```

### 线程的名称

每个线程默认有一个名字，尽管上面的例子中没有指定线程对象的`name`，但是Python会自动**为线程指定一个名字**。

我们可以通过`threading.enumerate()`函数查看当前的线程列表，通过`len(list)`函数即可获得当前线程的数量：

```python
import threading
import time

def greet():
    print('hello')
    time.sleep(2)

if __name__ == '__main__':
    for i in range(5):
        t = threading.Thread(target=greet)
        t.start()             # 每次循环都会创建并启动一个线程
    print('当前有%d条线程如下：' % len(threading.enumerate()))  	# 6，打印了当前线程的条数
    print(threading.enumerate())           # 当前线程的列表
```

打印列表大概如下：`[<_MainThread(MainThread, started 25132)>, <Thread(Thread-1, started 6840)>, <...`其中`_MainThread`就是主线程，`Thread`就是子线程。由于每次循环都创建一个子线程，再加上主线程，至少会有6个线程。

### 自定义线程类

线程的启动本质上是执行`Thread`类的`run`方法,当线程的`run()`方法结束时该线程完成。

因此，为了提升线程的封装性，我们可以添加一个新的子类，继承`threading.Thread`类，通过改写其`run()`方法实现，例如：

```python
import threading
import time

class MyThread(threading.Thread):
    def run(self):
        for i in range(3):
            time.sleep(1)
            msg = "I'm " + self.name + ' @ ' + str(i)  # name属性中保存的是当前线程的名字
            print(msg)

if __name__ == '__main__':
    t = MyThread()
    t.start()
```

可见，调用`start()`方法后，子类中的`run()`方法被执行。

### 线程的不确定性

线程的执行顺序是随机的，举个例子：

```python
import threading
import time

class MyThread(threading.Thread):
    def run(self):
        for i in range(3):
            time.sleep(1)
            msg = "I'm "+self.name + ' @ ' + str(i)
            print(msg)
            
def test():
    for i in range(5):
        t = MyThread()	
        t.start()	# 每次循环都会创建并启动一个线程
    	
if __name__ == '__main__':
    test()
```

从代码和执行结果我们可以看出，多线程程序的执行顺序是不确定的。当执行到`sleep`语句时，线程将被阻塞（Blocked ），到`sleep`结束后，线程进入就绪（Runnable ）状态，等待调度。而线程调度将**自行选择**一个线程执行。

上面的代码中只能保证每个线程都运行完整个`run()`函数，但是线程的启动顺序、`run()`函数中每次循环的执行顺序都不能确定。我们无法控制线程调度程序，这由操作系统决定，但可以通过别的方式间接影响线程调度的方式。

我们也注意到，一些换行出现了问题，我们在下面会解释这种现象出现的原因。

### 线程与全局变量

线程之间可以共享一个全局变量，例如：

```python
import threading

# 定义一个全局变量
g_num = 100

def test1():
    global g_num
    g_num += 1	# 全局变量加一
    print("在test1中，g_num = %d" % g_num)

def test2():
    print("在test2中，g_num = %d" % g_num)

def main():
    t1 = threading.Thread(target=test1)	# 定义两个线程
    t2 = threading.Thread(target=test2)

    t1.start()
    time.sleep(1)

    t2.start()
    time.sleep(1)

    print("在main中，g_num = %d" % g_num)

if __name__ == "__main__":
    main()

'''
打印结果：
在test1中，g_num = 101
在test2中，g_num = 101
在main中，g_num = 101
可见对形参的影响对后续线程的执行产生了影响
'''
```

也可以将全局变量传递作为参数传递到函数中：

```python
import threading
import time

def test1(temp):
    temp.append(33)	# 添加一个元素33
    print("在test1中，g_nums = %s" % g_nums)

def test2(temp):
    print("在test2中，g_nums = %s" % g_nums)

g_nums = [11, 22]

def main():
    t1 = threading.Thread(target=test1, args=(g_nums,))  # 传参并创建线程
    t2 = threading.Thread(target=test2, args=(g_nums,))

    t1.start()
    time.sleep(1)

    t2.start()
    time.sleep(1)

    print("在main中，g_nums = %s" % g_nums)

if __name__ == "__main__":
    main()
    
'''
打印结果：
在test1中，g_nums = [11, 22, 33]
在test2中，g_nums = [11, 22, 33]
在main中，g_nums = [11, 22, 33]
可见对形参的影响对后续线程的执行产生了影响
'''
```

我们再看一个示例：

```python
import time
import threading
# 定义一个全局变量
g_num = 0

def test1(num):
    global g_num
    for i in range(num):
        g_num += 1      # 每次加一，加num次
    print("在test1中，g_num = %d" % g_num)

def test2(num):
    global g_num
    for i in range(num):
        g_num += 1      # 每次加一，加num次
    print("在test2中，g_num = %d" % g_num)

def main():
    t1 = threading.Thread(target=test1, args=(10000000,))   # 传入参数
    t2 = threading.Thread(target=test2, args=(10000000,))

    t1.start()
    t2.start()

    # 等待上面的2个线程执行完毕....
    time.sleep(5)

    print("在main中，g_num = %d" % g_num)  # 预期为20000000，因为加法执行了20000000次

if __name__ == "__main__":
    main()
```

共对全局变量`g_num`执行了20000000次加1运算，预期结果应为20000000，但实际结果却为：

```python
在test1中，g_num = 10216872
在test2中，g_num = 11809532
在main中，g_num = 11809532
```

为什么会这样呢？原因是线程的**资源竞争问题**：

每执行一条语句，其实在计算机内部要执行很多次操作。

由于并行是在线程间做高速切换，操作系统会主动对线程进行调度。操作系统会随机将一个线程变为可执行状态（runnable ），执行一段时间后将其变为停止状态`sleeping`，将其它线程变为可执行状态（runnable ）。

以`+=`操作为例，计算机要先对变量做加法，再用新值覆盖原变量，就可能出现问题，以上面的程序为例：

1. 在`g_num=0`时，`t1`取得`g_num=0`。此时系统把`t1`调度为`sleeping`状态，把`t2`转换为`running`状态，`t2`也获得`g_num=0` ；
2. `t2`对得到的值进行加1并赋给`g_num`，使得`g_num=1` ；
3. 系统又把`t2`调度为`sleeping`，把`t1`转为`running`。线程`t1`又把它之前得到的`0`加`1`后赋值给`g_num`；
4. 这样导致虽然`t1`和`t2`都对`g_num`加1，但结果仍然是`g_num=1`。

上述打印操作的换行错乱问题也类似于这个原因。

## 同步

### 同步的概念

同步就是协同步调，按预定的**先后次序**进行运行，即你说完，我再说。

"同"在这里指**协同、协助、互相配合**，而非字面意义上理解的”一起动作“。

如进程、线程同步，可理解为进程或线程`A`和`B`一块配合，`A`执行到一定程度时要依靠`B`的某个结果，于是停下来，示意`B`运行；`B`执行，再将结果给`A`；`A`再继续操作。  

### 解决线程同时修改全局变量的方式 

对于上面提出的那个计算错误的问题，可以通过线程同步来进行解决：

1. 系统调用`t1`，然后获取到`g_num`的值为`0`，此时**上一把锁**，即不允许其他线程操作`g_num` ；
2. `t1`对`g_num`的值进行加`1` ；
3. `t1`**解锁**，此时`g_num`的值为`1`，其他的线程就可以使用`g_num`了，而且是`g_num`的值不是`0`而是`1` ；
4. 同理其他线程在对`g_num`进行修改时，都要先上锁，处理完后再解锁。在上锁的整个过程中不允许其他线程访问，就保证了数据的正确性。

### 互斥锁

**互斥锁**即为上面提到的**锁**，它为资源引入了一个状态：**锁定(locked)/非锁定(unlocked)** 。

某个线程要更改共享数据时，先将其锁定，此时资源的状态为`locked`，其他线程**不能更改**；直到该线程释放资源，将资源的状态变成`unlocked`，其他的线程才能再次锁定该资源。

`threading`模块中定义了`Lock`类，可以方便的处理锁定。

先使用构造方法`threading.Lock()`创建锁对象，创建后即可调用`acquire()`和`release()`方法进行上锁和解锁：

```python
# 创建锁对象
mutex = threading.Lock()

# 上锁
mutex.acquire()

# 解锁
mutex.release()
```

当一个线程调用锁的`acquire()`方法获得锁时，锁就进入`locked`状态。 每次只有一个线程可以获得锁。如果此时另一个线程试图获得这个锁，该线程就会变为`blocked`状态，称为**阻塞**；直到拥有锁的线程调用锁的`release()`方法释放锁之后，锁进入`unlocked`状态。 线程调度程序从处于同步阻塞状态的线程中选择一个来获得锁，并使得该线程进入运行`running`状态。

互斥锁**保证了每次只有一个线程进行写入操作**，从而保证了多线程情况下数据的正确性。

注意：

+ 如果这个锁之前是没有上锁的，那么`acquire`不会堵塞，会被正常执行上锁操作；
+ 如果在调用`acquire`对这个锁上锁之前已被其他线程上了锁，那么此时`acquire`会堵塞，直到这个锁被解锁为止。

于是，上面的程序可以改写如下：

```python
import time
import threading
# 定义一个全局变量
g_num = 0
# 创建一个锁对象，供全局使用
mutex = threading.Lock()

def test1(num):
    global g_num
    for i in range(num):
        mutex.acquire()  # 上锁
        g_num += 1       # 每次加一，加num次
        mutex.release()  # 解锁
    print("在test1中，g_num = %d" % g_num)

def test2(num):
    global g_num
    for i in range(num):
        mutex.acquire()  # 上锁
        g_num += 1       # 每次加一，加num次
        mutex.release()  # 解锁
    print("在test2中，g_num = %d" % g_num)

def main():
    t1 = threading.Thread(target=test1, args=(10000000,))   # 传入参数
    t2 = threading.Thread(target=test2, args=(10000000,))

    t1.start()
    t2.start()

    # 等待上面的2个线程执行完毕....
    time.sleep(5)

    print("在main中，g_num = %d" % g_num)  # 预期为20000000，因为加法执行了20000000次

if __name__ == "__main__":
    main()
```

执行结果如下：

```python
在main中，g_num = 15031572
在test1中，g_num = 19594391
在test2中，g_num = 20000000
```

可见最终结果符合预期，解决了资源竞争的问题。

锁的好处： 

+ 确保了某段关键代码只能由一个线程从头到尾完整地执行，保证了执行的**正确性**

锁的坏处：

+ 阻止了多线程并发执行，包含锁的某段代码**实际上只能以单线程模式执行**，效率就大大地下降了 
+ 由于可以存在多个锁，不同的线程持有不同的锁，并试图获取对方持有的锁时，可能会造成**死锁**

### 死锁

在线程间共享多个资源的时候，如果两个线程分别占有一部分资源并且同时等待对方的资源，就会造成**死锁**。 

尽管死锁很少发生，但一旦发生就会造成应用的**停止响应**。下面看一个死锁的例子：

```python
import threading
import time

class MyThread1(threading.Thread):
    def run(self):
        # 对mutexA上锁
        mutexA.acquire()

        # mutexA上锁后，延时1秒，等待另外那个线程 把mutexB上锁
        print(self.name+'----do1---up----')
        time.sleep(1)

        # 此时会堵塞，因为这个mutexB已经被另外的线程抢先上锁了
        mutexB.acquire()
        print(self.name+'----do1---down----')
        mutexB.release()

        # 对mutexA解锁
        mutexA.release()


class MyThread2(threading.Thread):
    def run(self):
        # 对mutexB上锁
        mutexB.acquire()

        # mutexB上锁后，延时1秒，等待另外那个线程 把mutexA上锁
        print(self.name+'----do2---up----')
        time.sleep(1)

        # 此时会堵塞，因为这个mutexA已经被另外的线程抢先上锁了
        mutexA.acquire()
        print(self.name+'----do2---down----')
        mutexA.release()

        # 对mutexB解锁
        mutexB.release()

mutexA = threading.Lock()
mutexB = threading.Lock()

if __name__ == '__main__':
    t1 = MyThread1()
    t2 = MyThread2()
    t1.start()
    t2.start()
```

在这个案例中，两把锁都为阻塞状态，而无法执行到解锁逻辑（虽然定义了，却会被另一线程抢先上锁，导致无法到达 ）。

一般写程序时不怎么会遇到死锁，要避免死锁可以参考**银行家算法**，或**添加超时时间**（一般用不到，了解即可 ）。

## 附录-银行家算法：

### 背景

一个银行家如何将一定数目的资金安全地借给若干个客户，使这些客户**既能借到钱完成要干的事**，同时银行家又能**收回全部资金而不至于破产**，这就是银行家问题。

这个问题同操作系统中资源分配问题十分相似：银行家就像一个操作系统，客户就像运行的进程，银行家的资金就是系统的资源。 

### 问题的描述

一个银行家拥有一定数量的资金，有若干个客户要贷款。每个客户须在一开始就声明他所需贷款的总额。若该客户贷款总额不超过银行家的资金总数，银行家可以接收客户的要求。客户贷款是以每次一个资金单位（如1万RMB等 ）的方式进行的，客户在借满所需的全部单位款额之前可能会等待，但银行家须保证这种等待是有限的，可完成的。 

### 举例

例如：有三个客户`C1`，`C2`，`C3`，向银行家借款，该银行家的资金总额为10个资金单位，其中`C1`客户要借9各资金单位，`C2`客户要借3个资金单位，`C3`客户要借8个资金单位，总计20个资金单位。某一时刻的状态如图所示：

![img](https://images.drshw.tech/images/notes/thread213412-image.png)

对于第一张图的状态，按照安全序列的要求，我们选的第一个客户应满足该客户所需的贷款小于等于银行家当前所剩余的钱款，可以看出只有`C2`客户能被满足：`C2`客户需`1`个资金单位，小银行家手中的`2`个资金单位，于是银行家把`1`个资金单位借给`C2`客户，使之完成工作并归还所借的`3`个资金单位的钱，到达第二张图的状态。

同理，银行家把`4`个资金单位借给`C3`客户，使其完成工作，在第三张图中，只剩一个客户`C1`，它需`7`个资金单位，这时银行家有`8`个资金单位，所以`C1`也能顺利借到钱并完成工作。

对于第四张图，银行家收回全部`10`个资金单位，保证不赔本。那么客户序列`{C1，C2，C3}`就是个安全序列，按照这个序列贷款，银行家才是安全的。否则的话，若在图二状态时，银行家把手中的`4`个资金单位借给了`C1`，则出现不安全状态：这时`C1`、`C3`均不能完成工作，而银行家手中又没有钱了，系统陷入僵持局面，银行家也不能收回投资。

综上所述，银行家算法是从当前状态出发，逐个按安全序列检查各客户谁能完成其工作，然后假定其完成工作且归还全部贷款，再进而检查下一个能完成工作的客户，以此类推。如果所有客户都能完成工作，则找到一个安全序列，银行家才是安全的。

更详细的介绍可见[操作系统——死锁的检测与解除](https://docs.drshw.tech/os/3/4/#343-%E9%81%BF%E5%85%8D%E6%AD%BB%E9%94%81)一章
