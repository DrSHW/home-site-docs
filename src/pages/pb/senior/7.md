---
description: Docs intro
layout: ../../../layouts/MainLayout.astro
---

# 多任务——进程

## 概述

### 什么是进程

一个程序运行起来后，**代码+用到的资源**称之为进程，它是**操作系统分配资源**的基本单元。

我们不仅可以通过线程完成多任务，也可以通过进程完成。

### 进程的状态

工作中，任务数往往大于CPU的核数，即一定有一些任务正在执行，而另外一些任务在等待CPU进行执行。

因此，任务进程有了不同的状态：

![image.png](https://images.drshw.tech/images/notes/%E9%98%BF%E8%90%A8%E5%BE%B7%E5%8F%AF%E8%83%BD%E5%8F%91%E7%94%9F%E7%9A%84%E4%BA%86%E5%92%96%E5%95%A1%E7%99%BB%E9%99%86.png)

+ 就绪态：运行的条件都已经具备，正在等在CPU执行；

+ 执行态：CPU正在执行其功能；
+ 等待态：等待某些条件满足，例如一个程序状态为`sleeping`了，此时就处于等待态。

## multiprocessing模块

### 进程的创建

`multiprocessing`模块就是跨平台版本的多进程模块，提供了一个`Process`类来代表一个进程对象，这个对象可以理解为是一个独立的进程，可以执行另外的事情。

与`threading`模块的`Thread`类相似，我们可以给`Process`类指定一个进程需要执行的方法，格式类似`Thread`类：

```python
from multiprocessing import Process
p = Process(target=函数/方法名, args=参数)
```

其中`target`和`args`参数的意义与`Thread`类的一致，要启动进程，执行`p.start()`即可，示例：

```python
from multiprocessing import Process
import time

def run_proc():
    """ 子进程要执行的代码 """
    while True:
        print("----2----")
        time.sleep(1)

if __name__=='__main__':
    p = Process(target=run_proc)
    p.start()
    while True:
        print("----1----")
        time.sleep(1)
```

运行后可以看到两个`while`死循环交替执行。

### 进程的pid

在操作系统中，每一个进程都有一个唯一的**进程号(pid)**，来标志这个进程。调用`os`模块中的`getpid()`函数可获取当前进程的进程号：

示例：

```python
from multiprocessing import Process
import os
import time

def run_proc():
    """子进程要执行的代码"""
    print('子进程运行中，pid=%d...' % os.getpid())  # os.getpid获取当前进程的进程号
    print('子进程将要结束...')

if __name__ == '__main__':
    print('父进程pid: %d' % os.getpid())  # os.getpid获取当前进程的进程号
    p = Process(target=run_proc)
    p.start()
```

### Process类及对象的其他语法

构造方法`Process(group, target, name, args, kwargs)` 的参数：

+ `target`：如果传递了函数的引用，可以任务这个子进程就执行这里的代码； 

+ `args`：给`target`指定的函数传递的参数，以元组的方式传递； 
+ `kwargs`：给`target`指定的函数传递命名参数； 
+ `name`：给进程设定一个名字，可以不设定；
+ `group`：指定进程组，大多数情况下用不到`Process`创建的实例对象的。

常用方法： 

+ `start()`：启动子进程实例（创建子进程 ）；
+ `is_alive()`：判断进程子进程是否还在活着；
+ `join([timeout])`：是否等待子进程执行结束，或等待多少秒，默认为等待子进程执行完毕后再执行后续代码。
+ `terminate()`：不管任务是否完成，**立即终止**子进程`Process`创建的实例对象的

常用属性： 

+ `name`：当前进程的别名，默认为`Process-N`，`N`为从`1`开始递增的整数 
+ `pid`：当前进程的`pid`（进程号 ）

创建进程并传递函数参数示例：

```python
from multiprocessing import Process
import os
from time import sleep

def run_proc(name, age, **kwargs):
    for i in range(10):
        print('子进程运行中，name= %s,age=%d ,pid=%d...' % (name, age, os.getpid()))
        print(kwargs)
        sleep(0.2)

if __name__=='__main__':
    p = Process(target=run_proc, args=('test',18), kwargs={"m":20})
    p.start()
    sleep(1)  # 1秒中之后，立即结束子进程
    p.terminate()
    p.join()
```

运行结果：

```python
子进程运行中，name= test,age=18 ,pid=28960...
{'m': 20}
子进程运行中，name= test,age=18 ,pid=28960...
{'m': 20}
子进程运行中，name= test,age=18 ,pid=28960...
{'m': 20}
子进程运行中，name= test,age=18 ,pid=28960...
{'m': 20}
```

### 进程与全局变量

与线程不同，进程之间不共享全局变量，举个例子：

```python
from multiprocessing import Process
import os
import time

nums = [11, 22]

def work1():
    """ 子进程要执行的代码 """
    print("in process1 pid=%d ,nums=%s" % (os.getpid(), nums))
    for i in range(3):
        nums.append(i)
        time.sleep(1)
        print("in process1 pid=%d ,nums=%s" % (os.getpid(), nums))

def work2():
    """ 子进程要执行的代码 """
    print("in process2 pid=%d ,nums=%s" % (os.getpid(), nums))

if __name__ == '__main__':
    p1 = Process(target=work1)
    p1.start()
    p1.join()
    p2 = Process(target=work2)
    p2.start()
```

运行结果：

````python
in process1 pid=22460 ,nums=[11, 22]
in process1 pid=22460 ,nums=[11, 22, 0]
in process1 pid=22460 ,nums=[11, 22, 0, 1]
in process1 pid=22460 ,nums=[11, 22, 0, 1, 2]
in process2 pid=23780 ,nums=[11, 22]
````

## 进程与线程的对比

### 功能的不同

+ 进程，能够完成多任务，比如 在一台电脑上能够同时运行多个QQ；
+ 线程，能够完成多任务，比如 一个QQ中的多个聊天窗口。

### 定义的不同

+ 进程是系统进行资源分配和调度的一个独立单位；
+ 线程是进程的一个实体，是CPU调度和操作系统分派的基本单位，它是比进程更小的能独立运行的基本单位；
+ 线程自己基本上不拥有系统资源，只拥有一点在运行中必不可少的资源(如程序计数器，一组寄存器和栈)，但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源。

### 其他区别 

+ 一个程序至少有一个进程，一个进程至少有一个线程；
+ 线程的划分尺度小于进程(资源比进程少)，使得多线程程序的并发性高； 
+ 进程在执行过程中拥有独立的内存单元，而多个线程共享内存，从而极大地提高了程序的运行效率；
+ 线程不能够独立执行，必须依存在进程中；
+ 可以将进程理解为工厂中的一条流水线，而其中的线程就是这个流水线上的工人；

### 优缺点 

线程和进程在使用上各有优缺点：线程执行开销小，但不利于资源的管理和保护；而进程正相反。

## 进程间通信

`Process`之间有时需要通信，操作系统提供了很多机制来实现进程间的通信，消息队列`Queue`使用的较多。

### Queue的简介

可以使用`multiprocessing`模块的`Queue`实现多进程之间的数据传递。

`Queue`本身是一个消息列队程序，也是一个类，需要实例化对象后使用。首先用一个小实例来演示一下`Queue`的工作原理：

```python
import queue            # queue.Full是队列满了的异常，捕获异常时使用
from multiprocessing import Queue

q = Queue(3)  # 初始化一个Queue对象，最多可接收三条put消息
q.put("消息1")
q.put("消息2")
print(q.full())  # False
q.put("消息3")
print(q.full())  # True

# 因为消息列队已满，故可使用try...except捕获队列已满异常（if判断更推荐 ）
# 第一个try会等待2秒后再抛出异常，第二个Try会立刻抛出异常
try:
    q.put("消息4", True, 2)
except queue.Full as e:     # 捕获队列已满异常
    print("消息列队已满，现有消息数量:%s" % q.qsize())

try:
    q.put_nowait("消息4")
except queue.Full as e:
    print("消息列队已满，现有消息数量:%s" % q.qsize())

# 推荐的方式，先判断消息列队是否已满，再写入
if not q.full():
    q.put_nowait("消息4")

# 读取消息时，先判断消息列队是否为空，再读取
if not q.empty():
    for i in range(q.qsize()):
        print(q.get_nowait())
```

运行结果：

```python
False
True
消息列队已满，现有消息数量:3
消息列队已满，现有消息数量:3
消息1
消息2
消息3
```

### Queue的使用

初始化`Queue()`对象时（例如：`q = Queue()` ），若括号中没有指定最大可接收的消息数量，或数量为负值，那么就代表可接受的消息数量没有上限（直到内存的尽头 ）；

+ `Queue.qsize()`：返回当前队列包含的消息数量；

+ `Queue.empty()`：如果队列为空，返回`True`，反之`False` ；

+ `Queue.full()`：如果队列满了，返回`True`，反之`False`；

+ `Queue.get(block, timeout)`：获取队列中的一条消息，然后将其从列队中移除，`block`默认值为`True`；

  + 如果`block`使用默认值，且没有设置`timeout`（单位秒 ），消息列队如果为空，此时程序将被阻塞（停在读取状态 ），直到从消息列队读到消息为止，如果设置了`timeout`，则会等待`timeout`秒，若还没读取到任何消息，则抛出`Queue.Empty`异常；

  + 如果`block`值为`False`，消息列队如果为空，则会立刻抛出`queue.Empty`异常；

+ `Queue.get_nowait()`：相当`Queue.get(False)`；

+ `Queue.put(item, block, timeout)`：将`item`消息写入队列，`block`默认值为`True`；

  + 如果`block`使用默认值，且没有设置`timeout`（单位秒 ），消息列队如果已经没有空间可写入，此时程序将被阻塞（停在写入状态 ），直到从消息列队腾出空间为止，如果设置了`timeout`，则会等待`timeout`秒，若还没空间，则抛出`Queue.Full`异常；

  + 如果`block`值为`False`，消息列队如果没有空间可写入，则会立刻抛出`Queue.Full`异常；

+ `Queue.put_nowait(item)`：相当于`Queue.put(item, False)`；

### 实例 

我们使用`Queue`实现：在父进程中创建两个子进程，一个往`Queue`里写数据，一个从`Queue`里读数据：

```python
import random
import time
from multiprocessing import Process, Queue

# 写数据进程执行的代码:
def write(q):
    for value in ['A', 'B', 'C']:
        print('Put %s to queue...' % value)
        q.put(value)
        time.sleep(random.random())

# 读数据进程执行的代码:
def read(q):
    while True:
        if not q.empty():           # 读完队列的内容后（即队列的状态为空 ）则退出循环
            value = q.get(True)
            print('Get %s from queue.' % value)
            time.sleep(random.random())
        else:
            break

if __name__=='__main__':
    # 父进程创建Queue，并传给各个子进程：（Queue的对象为可变类型，传入函数后可以被改变 ）
    q = Queue()
    pw = Process(target=write, args=(q,))
    pr = Process(target=read, args=(q,))
    # 启动子进程pw，写入:
    pw.start()    
    # 等待pw结束:
    pw.join()
    # 启动子进程pr，读取:
    pr.start()
    # 等待pr结束
    pr.join()
    print('所有数据都写入并且读完')
```

执行结果：

```python
Put A to queue...
Put B to queue...
Put C to queue...
Get A from queue.
Get B from queue.
Get C from queue.
所有数据都写入并且读完
```

## 进程池Pool

### 进程池的简介与初始化

当需要创建的子进程数量不多时，可以直接利用`multiprocessing`中的`Process`动态成生多个进程，但如果是上百甚至上千个目标，手动的去创建进程的工作量巨大，此时就可以用到`multiprocessing`模块提供的`Pool`方法。 

初始化`Pool`时，可以指定一个**最大进程数**，当有新的请求提交到`Pool`中时，如果池还没有满，那么就会创建一个新的进程用来执行该请求；但如果池中的进程数已经达到指定的最大值，那么该请求就会等待，直到池中有进程结束，才会用之前的进程来执行新的任务。

初始化格式为：`multiprocessing.Pool(num)`，`num`即为最大进程数，一般为`CPU核数`左右，不超过`CPU核数*2`，可调用`multiprocessing.cpu_count()`获取。

### 进程池对象的方法

+ `apply_async(func, args, kwds)` ：使用非阻塞方式调用`func`（并行执行，堵塞方式必须等待上一个进程退出才能执行下一个进程 ），`args`为传递给`func`的参数列表，`kwds`为传递给`func`的关键字参数列表；

  它会返回一个`multiprocessing.pool.ApplyResult`对象，通过调用其`get()`方法，即可得到`func()`函数返回值，要注意`get()`方法是同步阻塞方法；

  可添加`callback`参数指定回调函数，例如`callback=func`，它会在任务完成后将返回结果作为`func`的参数，并执行`func`。

+ `close()`：关闭`Pool`，使其不再接受新的任务；

+ `terminate()`：不管任务是否完成，立即终止；

+ `join()`：主进程阻塞，等待子进程的退出， 必须在`close`或`terminate`之后使用；

+ `map()`：非常强大的方法，传入一个函数`func`和一个可迭代对象`it`，会遍历这个可迭代对象，将**迭代结果作为参数**传递给`func`，并分配进程任务给`func`；执行该方法时进程池关闭，不再接收新任务；且主线程阻塞，等待子进程执行完毕后才退出阻塞；返回一个结果列表，储存所有进程执行`func`的返回值；

要注意的是，进程池的操作需要在`main`函数中进行，不然可能会报`RuntimeError`的异常。

示例：

```python
from multiprocessing import Pool, cpu_count
import os, time, random

def worker(msg):
    t_start = time.time()
    print("%s开始执行,进程号为%d" % (msg, os.getpid()))
    # random.random()随机生成0~1之间的浮点数
    time.sleep(random.random() * 2)
    t_stop = time.time()
    print(msg, "执行完毕，耗时%0.2f" % (t_stop - t_start))

if __name__ == '__main__':
    # 获取cpu核心数，依据此数量开启进程池
    cpu_count = cpu_count()
    print("cpu核心数为%d" % cpu_count)
    po = Pool(cpu_count)
    for i in range(0, cpu_count):
        po.apply_async(worker, (i,))
    print("----start----")
    po.close()  # 关闭进程池，关闭后po不再接收新的请求
    po.join()  # 等待po中所有子进程执行完成，必须放在close语句之后
    print("-----end-----")
```

执行结果如下：

```python
cpu核心数为16
----start----
0开始执行,进程号为3048
1开始执行,进程号为38356
2开始执行,进程号为22844
3开始执行,进程号为9576
4开始执行,进程号为27464
5开始执行,进程号为35496
6开始执行,进程号为12424
7开始执行,进程号为1536
8开始执行,进程号为4120
9开始执行,进程号为23044
10开始执行,进程号为32884
11开始执行,进程号为7508
12开始执行,进程号为37068
13开始执行,进程号为9504
14开始执行,进程号为25620
15开始执行,进程号为36016
14 执行完毕，耗时0.02
7 执行完毕，耗时0.09
8 执行完毕，耗时0.26
9 执行完毕，耗时0.30
12 执行完毕，耗时0.35
4 执行完毕，耗时0.60
1 执行完毕，耗时0.74
0 执行完毕，耗时0.84
3 执行完毕，耗时0.79
6 执行完毕，耗时0.67
2 执行完毕，耗时1.12
5 执行完毕，耗时1.04
10 执行完毕，耗时1.16
11 执行完毕，耗时1.32
13 执行完毕，耗时1.54
15 执行完毕，耗时1.57
-----end-----
```

我们发现，执行过程确实是非阻塞（异步）的。

但是如果将结果改为，执行结束后打印返回值的形式，如下：

```python
from multiprocessing import Pool, cpu_count
import os, time, random

def worker(msg):
    t_start = time.time()
    print("%s开始执行,进程号为%d" % (msg, os.getpid()))
    # random.random()随机生成0~1之间的浮点数
    time.sleep(random.random() * 2)
    t_stop = time.time()
    res = str(msg) + ("执行完毕，耗时%0.2f" % (t_stop - t_start))
    return res		# 返回一个字符串

if __name__ == '__main__':
    # 获取cpu核心数，依据此数量开启进程池
    cpu_count = cpu_count()
    print("cpu核心数为%d" % cpu_count)
    print("----start----")
    po = Pool(cpu_count)
    for i in range(0, cpu_count):
        ret = po.apply_async(worker, (i,))
        print(ret.get())		# 接收返回值并打印，同步阻塞
    po.close()  # 关闭进程池，关闭后po不再接收新的请求
    po.join()  # 等待po中所有子进程执行完成，必须放在close语句之后
    print("-----end-----")
```

程序的执行会变为同步，原因是打印的结果必须在程序结束后才能执行，存在了**上下的依赖关系**，无法异步执行。

要解决这个问题，提前定义一个列表将`ret`对象保存起来即可：

```python
from multiprocessing import Pool, cpu_count
import os, time, random

def worker(msg):
    t_start = time.time()
    print("%s开始执行,进程号为%d" % (msg, os.getpid()))
    # random.random()随机生成0~1之间的浮点数
    time.sleep(random.random() * 2)
    t_stop = time.time()
    res = str(msg) + ("执行完毕，耗时%0.2f" % (t_stop - t_start))
    print(res)
    return os.getpid()

if __name__ == '__main__':
    ret_list = []
    # 获取cpu核心数，依据此数量开启进程池
    cpu_count = cpu_count()
    print("cpu核心数为%d" % cpu_count)
    print("----start----")
    po = Pool(cpu_count)
    for i in range(0, cpu_count):
        ret = po.apply_async(worker, (i,))
        ret_list.append(ret)		# 将对象直接放入列表，不需要提供执行结果
    po.close()  # 关闭进程池，关闭后po不再接收新的请求
    po.join()  # 等待po中所有子进程执行完成，必须放在close语句之后
    print("----end----")
    print("----res----")
    for ret in ret_list:
        print(ret.get())
```

这样在执行时，只要把`apply_async`生成的`ret`整个地放入`list`中（此时还不携带返回值），不依赖执行结果。当该进程执行结束后，会给相对应的对象赋予结果，在列表中进行同步（内存是同一块），在任务全部完成时打印即可。当然最简单的还是使用`map()`方法：

```python
...
print("----start----")
ret_list = po.map(worker, range(cpu_count))
print("----end----")
print("----res----")
for ret in ret_list:
	print(ret.get())
```

或者使用回调函数实现：

```python
from multiprocessing import Pool, cpu_count
import os, time, random

def worker(msg):
    t_start = time.time()
    print("%s开始执行,进程号为%d" % (msg, os.getpid()))
    # random.random()随机生成0~1之间的浮点数
    time.sleep(random.random() * 2)
    t_stop = time.time()
    res = str(msg) + ("执行完毕，耗时%0.2f" % (t_stop - t_start))
    return res		# 返回一个字符串

def finished(res):
    print(res)

if __name__ == '__main__':
    # 获取cpu核心数，依据此数量开启进程池
    cpu_count = cpu_count()
    print("cpu核心数为%d" % cpu_count)
    print("----start----")
    po = Pool(cpu_count)
    for i in range(0, cpu_count):
        ret = po.apply_async(worker, (i,), callback=finished)
    po.close()  # 关闭进程池，关闭后po不再接收新的请求
    po.join()  # 等待po中所有子进程执行完成，必须放在close语句之后
    print("-----end-----")
```

### 进程池中的Queue 

如果要使用`Pool`创建进程，就需要使用`multiprocessing.Manager()`中的`Queue()`，而不是`multiprocessing.Queue()`，否则会得到一条如下的错误信息： 

```bash
RuntimeError: Queue objects should only be shared between processes through inheritance. 
```

下面的示例演示了进程池中的进程如何通信：

```python
# 修改import中的Queue为Manager
from multiprocessing import Manager, Pool
import os, time, random

def reader(q):
    print("reader启动(%s),父进程为(%s)" % (os.getpid(), os.getppid()))
    for i in range(q.qsize()):
        print("reader从Queue获取到消息：%s" % q.get(True))

def writer(q):
    print("writer启动(%s),父进程为(%s)" % (os.getpid(), os.getppid()))
    for i in "DrSHW":
        q.put(i)

if __name__=="__main__":
    print("(%s) start" % os.getpid())
    q = Manager().Queue()  # 需要使用Manager中的Queue
    po = Pool()
    po.apply_async(writer, (q, ))

    time.sleep(1)  # 先让上面的任务向Queue存入数据，然后再让下面的任务开始从中取数据

    po.apply_async(reader, (q, ))
    po.close()
    po.join()
    print("(%s) End" % os.getpid())

```

执行结果如下：

```python
(2484) start
writer启动(26868),父进程为(2484)
reader启动(26868),父进程为(2484)
reader从Queue获取到消息：D
reader从Queue获取到消息：r
reader从Queue获取到消息：S
reader从Queue获取到消息：H
reader从Queue获取到消息：W
(2484) End
```

