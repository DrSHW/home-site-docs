---
description: Docs intro
layout: ../../../layouts/MainLayout.astro
---

# 数据预处理

在工程实践中，我们得到的数据会存在有缺失值、重复值等，在使用之前需要进行数据预处理。数据预处理没有标准的流程，通常针对不同的任务和数据集属性的不同而不同。数据预处理的常用流程为：去除唯一属性、处理缺失值、属性编码、数据标准化正则化、特征选择、主成分分析。接下来，我们使用pandas中数据预处理的内容进行详细的数据进行解释。

## 数据清洗

数据清洗(Data Cleaning)指对数据进行重新审查和校验的过程，目的在于**删除重复信息**、**纠正存在的错误**，并提供数据一致性。数据清洗的目的在于提高数据的质量，将脏的数据（这里是指对数据分析没有实际意义的意义，格式非法，不在1指定1范围里的数据）清洗干净，使原有的数据具有完整性，唯一性，权威性，合法性，一致性等特点。

## 空值和缺失值的处理

缺失值处理，是每个数据分析人都避不开的沉重话题。正如那句经典的：“数据分析中的大部分时间，花在了数据预处理上。”数据预处理做得好，往往让我们的数据分析工作事半功倍。其中，正确处理缺失值，更是重中之重。出现这种的原因有那些呢？

1. 信息暂时无法获取。如某种产品的收益等具有滞后效应。
2. 数据因人为因素没有被记录、遗漏或丢失，这个是数据缺失的主要原因。
3. 数据采集设备的故障、存储介质、传输媒体故障而造成数据丢失。
4. 获取这些信息的代价太大。
5. 有些对象的某个或某些属性是不可用的；如：未婚者的配偶姓名、儿童的固定收入状况等。
6. 系统实时性能要求较高，即要求得到这些信息前迅速做出判断或决策。

其中这些对数据挖掘会有那些影响

1. 使系统丢失大量的有用信息；
2. 使系统中所表现出的不确定性更加显著，系统中蕴涵的确定性成分更难把握；
3. 包含空值的数据会使数据挖掘过程陷入混乱，导致不可靠的输出。

一般空值用`None`表示，缺失值使用`Nan`表示，Pandas中提共了一一些方法检查处理缺失值。其中使用`isnull`和`null`函数可以判断数据集中出现空值或者缺失值，对于缺失数据可以使用`dropna`，`fillna`方法进行删除填充，下面来介绍。

### isnull / notnull方法

我们可以通过`isnull`和`notnull`方法来判断数据表中是否存在缺失数据：

1. **isnull**

```python
from pandas import DataFrame, Series
import pandas as pd
from numpy import NaN
series_obj = pd.Series([1, None, NaN])
pd.isnull(series_obj)       # 检查是否为空值或缺失值
```

2. **notnull**

```python
from pandas import DataFrame, Series
import pandas as pd
from numpy import NaN
series_obj = Series([1, None, NaN])
pd.notnull(series_obj)       # 检查是否不为空值或缺失值
```

### fillna / dropna方法

若有一张表格里有缺省值，表格的创建如下：

```python
import pandas as pd
from numpy import NaN
df_obj = pd.DataFrame({'A': [1, 2, 3, NaN],
                       'B': [NaN, 4, NaN, 6],
                       'C':['a', 7, 8, 9],
                       'D':[NaN, 6.0, 9, NaN]
                       })
```

1. **fillna**

   如果使用常量`66.0`来替换缺省值，那么填充前后的效果如下图：

   ![1647497226861](https://images.maiquer.tech/images/wx/1647497226861.png)

   通过`fillna()`方法填充常量的示例如下:

   ```python
   df_obj.fillna('66.0')		# 使用66.0替换缺失值
   ```

   如果希望A列缺失的数据使用数字“4.0”进行填充，B列缺失的数据使用数字“5.0”来填，那么填充前后的效果如下图所示。

   ![1647497251350](https://images.maiquer.tech/images/wx/1647497251350.png)

   指定列填充数据需要传入一个字典，如下：

   ```python
   df_obj.fillna({'A': 4.0, 'B':5.0})
   ```

   如果希望A列缺失按从前往后的顺序填充缺失的数据，那么填充前后的效果如下图所示。

   ![1647497226861](https://images.maiquer.tech/images/wx/1647497515743.png)

   使用前向填充的方式替换空值或缺失值方法如下：

   ```python
   df.fillna(method='ffill')
   ```

2. **combine_first**

   当DataFrame对象中出现了缺失数据，而我们希望，使用**其他**DataFrame对象中的数据填充缺失数据，则可以通过`combine_first()`方法为缺失数据填充：

   ```
   combine_first(other)
   ```
   这个`other`参数是接受**缺失值**Dateframe对象的，例如：
   ```python
   import pandas as pd
   import numpy as np
   from numpy import NAN
   left = pd.DataFrame({'A': [np.nan, 'A1', 'A2', 'A3'],
                           'B': [np.nan, 'B1', np.nan, 'B3'],
                           'key': ['K0', 'K1', 'K2', 'K3']})
   right = pd.DataFrame({'A': ['C0', 'C1','C2'],
                            'B': ['D0', 'D1','D2']},
                            index=[1,0,2])
   # 用right的数据填充left缺失的部分
   left.combine_first(right) 
   ```

3. **dropna**

   `dropna`可以删除所有值为空的行或列，默认为删除行，指明轴可删除对应轴，如想删除列的数据指明`axis=1`即可：

   ```python
   import pandas as pd
   import numpy as np
   df_obj = pd.DataFrame({"类别":['小说', '散文随笔', '青春文学', '传记'],
                          "书名":[np.nan, '《皮囊》', '《旅程结束时》', '《老舍自传》'],
                          "作者":["老舍", None, "张其鑫", "老舍"]})
   df_obj
   ```

   ```python
   df_obj.dropna()     # 删除数据集中的空值和缺失值
   ```


## **重复值的处理**

数据清洗一般是现从重复值和缺失值开始处理的,重复值一般采用删除法来处理,但有些重复值不能删除，例如订单明细数据或交易明细数据等，pandas提共了两给方法专门用来处理数据中的重复值，分别为`duplicated()`和`drop_duplicates()`方法。其中，前者用于标记是否有重复值，后者用于删除重复值，它们的判断标准是一样的，即只要两条数据中**所有条目**的值完全相等，就判断为重复值。

### duplicated方法

​     格式：`duplicated(subset=None, keep=“first”)`

1. `subset`：用于识别重复的列标签或列标签序列，默认识别所有的列标签。

2. `keep`：删除重复项并保留第一次出现的项，取值可以为first、last、False，它们代表意义如下：	
- `first`：从前向后查找，除了**第一次**出现外，其余相同的被标记为重复。默认为此选项。
  
- `last`：从后向前查找，除了最后一次出现外，其余相同的被标记为重复。
  
- `False`：**所有**相同的都标记为重复。

`duplicated()`方法用于标记pandas对象的数据是否重复，重复则标记为`True`，不重复则标记为`False`，所以该方法返回一个由布尔值组成的`Series`对象，它的行索引保持不变，数据则变为标记的布尔值。

```python
import pandas as pd
person_info = pd.DataFrame({'id': [1, 2, 3, 4, 4, 5],
                            'name': ['小铭', '小月月', '彭岩', '刘华', '刘华', '周华'],
                            'age': [18, 18, 29, 58, 58, 36],
                            'height': [180, 180, 185, 175, 175, 178],
                            'gender': ['女', '女', '男', '男', '男', '男']})
person_info.duplicated()         # 从前向后查找和判断是否有重复值
```

### drop_duplicates方法
​	格式：`drop_duplicated(subset=None, keep=“first”, inplace=False)`

上述方法中， `inplace`表示是否在原数据上操作，如果设为`True`，则表示直接修改原数据，即**永久修改**；如果设为`False`，则表示修改原数据的副本，返回新数据，即**临时修改**，例如：

```python
import pandas as pd
person_info = pd.DataFrame({'id': [1, 2, 3, 4, 4, 5],
                            'name': ['小铭', '小月月', '彭岩', '刘华', '刘华', '周华'],
                            'age': [18, 18, 29, 58, 58, 36],
                            'height': [180, 180, 185, 175, 175, 178],
                            'gender': ['女', '女', '男', '男', '男', '男']})
person_info. drop_duplicates()
```

## 异常值的处理

**异常值分析**是检验数据是否有录入错误以及含有不合常理的数据；

**异常值**是指样本中的个别值,其数据明显偏离其余的观测值。异常值也称为离群点,异常值的分析也称为离群点分析。

**异常值处理**一般分为以下几个步骤：异常值检测、异常值筛选、异常值处理。

其中：

**异常值检测**的方法主要有：箱型图、简单统计量（比如观察极(大／小)值），`3σ`原则 ；

**异常值处理**方法主要有：删除法、插补法、替换法。

这些算法在这里作一个了解即可，若检测出了异常值，可使用`replace`方法进行替换：

​	格式：`replace(to_replace=None, value=None)`

​	其中`to_replace`代表要被替换的值，`value`代表替换后的值，例如：

```python
import pandas as pd
df = pd.DataFrame ({'菜谱名': ['红烧肉', '铁板鱿鱼', 
                    '小炒肉', '干锅鸭掌', '酸菜鱼'],
                    '价格': [38, 25, 26, 388, 35]})
df.replace(to_replace=388, value=38.8)
```

## 更改数据类型

在处理数据时，可能会遇到数据类型不一致的题。

例如，通过爬虫采集到的数据都是整型的数据，在使用数据时希望保留两位小数点，这时就需要将数据的类型转换成浮点型。

### dtypes属性

创建Pandas数据对象时，如果没有明确地指出数据的类型，则可以根据传入的数据推断出来，并且通过`dtypes`属性进行查看。

```python
df = pd.DataFrame( {'A':['5','6','7'],'B':['3','2','1']})	# 查看数据的类型
df.dtypes
object
```

还可以在创建Pandas对象时明确地指定数据的类型，即在使用构造方法中的`dtype`参数指定数据的类型。

```python
import pandas as pd
# 创建DataFrame对象，数据的类型为int
df = pd.DataFrame({'A': ['5', '6', '7'], 'B': ['3', '2', '1']},
                  dtype='int')
df.dtypes
```

### astype方法

![1647497226861](https://images.maiquer.tech/images/wx/1647497613346.png)

例如：

```python
import pandas as pd
df = pd.DataFrame({'A': ['1', '1.2', '4.2'],
                   'B': ['-9', '70', '88'],
                   'C': ['x', '5.0', '0']})
df.dtypes
df['B'].astype(dtype='int')  # 强制转换为int类型
```

`astype()`方法存在着一些局限性，只要待转换的数据中存在非数字字符，在使用`astype()`方法进行类型转换时就会出现错误，而`to_numeric()`函数的出现正好解决了这个问题。

![1647497226861](https://images.maiquer.tech/images/wx/1647497678930.png)

例如：

```python
import pandas as pd
ser_obj = pd.Series(['1', '1.2', '4.2'])
ser_obj
# 转换object类型为float类型
pd.to_numeric(ser_obj, errors='raise')
```

## 数据合并

Pandas包的`merge`、`join`、`concat`方法可以完成数据的合并和拼接，`merge`方法主要基于两个`Dataframe`的共同列进行合并，`join`方法主要基于两个`Dataframe`的索引进行合并，`concat`方法是对`Series`或`Dataframe`进行行拼接或列拼接。

### 轴向堆叠数据 concat

![1647497226861](https://images.maiquer.tech/images/wx/1647497744179.png)



![1647497226861](https://images.maiquer.tech/images/wx/1647497776522.png)

![1647497226861](https://images.maiquer.tech/images/wx/1647497805438.png)

若将`axis`参数的值设为`1`（选取横轴），且`join`参数的值设为`outer`，代表着使用横向堆叠与外连接的方式进行合并，例如下表：

![1647497226861](https://images.maiquer.tech/images/wx/1647497855844.png)

对应操作：

```python
import pandas as pd
df1 = pd.DataFrame({'A': ['A0', 'A0', 'A1'],
                    'B': ['B0', 'B0', 'B1']})
df2 = pd.DataFrame({'C': ['C0', 'C0', 'C1', 'C3'],
                    'D': ['D0', 'D2', 'D2', 'D3']})
df1
df2
# 按照横向堆叠合并df1和df2，采用外连接的方式
pd.concat([df1, df2], join='outer', axis=1)
```

若将`axis`参数的值设为`0`（选取纵轴），且`join`参数的值设为`inner`，则代表着使用纵向堆叠与内连接的方式进行合并，例如下表：



![1647497226861](https://images.maiquer.tech/images/wx/1647497910364.png)

对应操作：

```python
import pandas as pd
first = pd.DataFrame({'A': ['A0', 'A1', 'A2'],
                      'B': ['B0', 'B1', 'B2'],
                      'C': ['C0', 'C1', 'C2']})
second = pd.DataFrame({'B': ['B3', 'B4', 'B5'],
                       'C': ['C3', 'C4', 'C5'],
                       'D': ['D3', 'D4', 'D5']})
pd.concat([first, second], join='inner', axis=0)
```

### 主键合并 merge/join

主键合并类似于关系型数据库的连接方式，它是指根据一-个或多个键将不同的`DataFrame`对象连接起来，大多数是将两个`DatFrame`对象中重叠的列作为合并的键。

**1. merge方法**

pandas的`merge`方法是基于共同列，将两个`DataFrame`连接起来。

`merge`方法的主要参数：

![](https://images.maiquer.tech/images/wx/1647497946650.png)

1. `left/right`：左/右位置的`DataFrame`。
2. `how`：数据合并的方式。
   + `left`：基于左`DataFrame`列的数据合并；
   + `right`：基于右`DataFrame`列的数据合并；
   + `outer`：基于列的数据外合并（取并集）；
   + `inner`：默认，基于列的数据内合并（取交集）；
3. `on`：用来合并的列名，这个参数需要保证两个`DataFrame`有相同的列名。
4. `left_on/right_on`：左/右`DataFrame`合并的列名，也可为索引，数组和列表。
5. `left_index/right_index`：是否以`index`作为数据合并的列名，`True`表示是。
6. `sort`：根据`DataFrame`合并的`keys`排序，默认是。
7. `suffixes`：若有相同列且`DataFrame`该列没有作为合并的列，可通过`suffixes`设置该列的后缀名，一般为元组和列表类型。

`merges`通过设置`how`参数选择两个`DataFrame`的连接方式，有内连接，外连接，左连接，右连接，下面通过例子介绍连接的含义：

按照内连接，指定列名：

```python
import pandas as pd
left = pd.DataFrame({'key':['K0','K1','K2'],
                       'A':['A0','A1','A2'],
                        'B':['B0','B1','B2']})
right = pd.DataFrame({'key':['K0','K1','K2','K3'],
                         'C':['C0','C1','C2','C3'],
                         'D':['D0','D1','D2','D3']})
pd.merge(left, right, on='key')
```
指定多个列名连接：
```python
import pandas as pd
left = pd.DataFrame({'key':['K0','K1','K2'],
                       'A':['A0','A1','A2'],
                       'B':['B0','B1','B2']})
right = pd.DataFrame({'key':['K0','K5','K2','K4'],
                         'B':['B0','B1','B2','B5'],
                         'C':['C0','C1','C2','C3'],
                         'D':['D0','D1','D2','D3']})
pd.merge(left, right, on=['key', 'B'])
```
按照外连接，没有数据重合：

```python
import pandas as pd
left = pd.DataFrame({'A':['A0','A1','A2'],
                       'B':['B0','B1','B2']})
right = pd.DataFrame({'C':['C0','C1','C2'],
                         'D':['D0','D1','D2']})
pd.merge(left, right, how='outer', left_index=True, right_index=True)
```

**2. join方法**

![1647497226861](https://images.maiquer.tech/images/wx/1647498012311.png)

例如：

外连接方式：

```python
import pandas as pd
left = pd.DataFrame({'A': ['A0', 'A1', 'A2'],
                        'B': ['B0', 'B1', 'B2']})
right = pd.DataFrame({'C': ['C0', 'C1', 'C2'],
                         'D': ['D0', 'D1', 'D2']},
                        index=[ 'a','b','c'])
left.join(right, how='outer')
```
左连接，并指明参照列：
```python
import pandas as pd
left = pd.DataFrame({'A': ['A0', 'A1', 'A2'],
                        'B': ['B0', 'B1', 'B2'],
                      'key': ['K0', 'K1', 'K2']})
right = pd.DataFrame({'C': ['C0', 'C1','C2'],
                         'D': ['D0', 'D1','D2']},
                        index=['K0', 'K1','K2'])

left.join(right, how='left', on='key')		# on参数指定连接的列名
```

### 合并重塑数据 stack/unstack

![](https://images.maiquer.tech/images/wx/1647498053510.png)例如：


```python
import pandas as pd
df = pd.DataFrame({'A':['A0','A1','A2'],
                 'B':['B0','B1','B2']})
result = df.stack()						# 将df进行重塑
result
```

层次化索引合并：


```python
import pandas as pd
import numpy as np
df = pd.DataFrame(np.array([[26,20,22,26],[30,25,24,20]]),
                   index=['男生人数','女生人数'],
                   columns=[['一楼','一楼','二楼','二楼'],
                              ['A教室','B教室','A教室','B教室']])
df.stack()
df.stack(level=0)   # 旋转外层索引
```

![](https://images.maiquer.tech/images/wx/1647498090101.png)

例如：

```python
import pandas as pd
df = pd.DataFrame({'A':['A0','A1','A2'],
                      'B':['B0','B1','B2']})
res = df.stack()  			#　将df重塑为Series对象
res.unstack()      			#　将Series对象转换成df
```
### 重命名轴索引

pandas中提供了一个`rename()`方法来重命名个别列索引或行索引的标签或名称：

![](https://images.maiquer.tech/images/wx/1647498130186.png)

例如，将df对象的每个列索引重命名为`a,b,c`：

![](https://images.maiquer.tech/images/wx/1647498193304.png)

```python
import pandas as pd
df = pd.DataFrame({'A':['A0', 'A1', 'A2', 'A3'],
                 'B':['B0', 'B1', 'B2', 'B3'],
                 'C':['C0', 'C1', 'C2', 'C3']})
df
# 重命名列索引的名称，并且在原有数据上进行修改
df.rename(columns={'A':'a', 'B':'b', 'C':'c'}, inplace=True)
df
import pandas as pd
df = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],
                   'B': ['B0', 'B1', 'B2', 'B3'],
                   'C': ['C0', 'C1', 'C2', 'C3']})
df.rename(str.lower, axis=1)		# 改变列索引
df
import pandas as pd
df = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],
                    'B': ['B0', 'B1', 'B2', 'B3'],
                    'C': ['C0', 'C1', 'C2', 'C3']})
df.rename(index={1: 'a', 2: 'b'}, inplace=True)
df
```

### 轴向旋转 pivot

某件商品的价格在非活动期间为`50`元，而在活动期间商品的价格为`30`元，这就造成同一件商品在不同时间对应不同的价格。

在pandas中的`pivot()`方法提供了这样的功能，它会根据给定的行或列索引重新组织一个`DataFrame`对象。

```python
pivot(index=None, columns=None, values=None)
```

`index`: 用于创建新`DataFrame`对象的行索引。

`columns:` 用于创建新`DataFrame`对象的列索引。

`values`: 用于填充新`DataFrame`对象中的值。

例如：

```python
import pandas as pd
df =  pd.DataFrame({'商品名称': ['荣耀9青春版','小米6x','OPPO A1',
                   '荣耀9青春版','小米6x','OPPO A1'],
                   '出售日期': ['2020年5月25日', '2017年5月25日',
                   '2020年5月25日','2020年6月18日',
                   '2020年6月18日', '2020年6月18日'],
                   '价格': ['999元', '1399元', '1399元',
                   '800元', '1200元', '1250元']})
df
df.pivot(index='出售日期', columns='商品名称', values='价格')
```
