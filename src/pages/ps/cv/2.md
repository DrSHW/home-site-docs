---
description: Docs intro
layout: ../../../layouts/MainLayout.astro
---

# 深度学习与神经网络

## 第一章 机器学习

### 1.1 机器学习概述

从广义上来说，**机器学习**是一种能够赋予机器学习的能力以此让它完成**直接编程无法完成的功能的方法**。但从实践的意义上来说，机器学习是一种通过**利用训练数据，训练出模型，然后使用模型预测**的一种方法。

可用传统编程解决的任务举例：

<img src="https://images.drshw.tech/images/notes/image-20221209161815401.png" alt="image-20221209161815401" style="zoom:80%;" />

需要运用机器学习处理的任务举例：

<img src="https://images.drshw.tech/images/notes/image-20221209161841224.png" alt="image-20221209161841224" style="zoom:80%;" />

训练模型可以看成一个**函数映射关系**，输入为**特征变量**，输出**目标变量**。

举个例子，通过如下的训练数据（特征变量`x`、目标变量`y`）：

<img src="https://images.drshw.tech/images/notes/image-20221201115002054.png" alt="image-20221201115002054" style="zoom: 25%;" />

可得到训练好的**模型**：`y = f(x) = 2x + 1`，得到模型后，即可进行**预测**（计算`f(4) = 9`）。

各种机器学习领域中的模型也可以抽象为一个个函数映射关系，如：

+ 语音识别：

  <img src="https://images.drshw.tech/images/notes/image-20221201115712541.png" alt="image-20221201115712541" style="zoom:65%;" />

+ 图像识别：

  <img src="https://images.drshw.tech/images/notes/image-20221201115559510.png" alt="image-20221201115559510" style="zoom:33%;" />

+ Playing Game：

  <img src="https://images.drshw.tech/images/notes/image-20221201115631297.png" alt="image-20221201115631297" style="zoom:33%;" />

+ 对话系统：

  <img src="https://images.drshw.tech/images/notes/image-20221201115649698.png" alt="image-20221201115649698" style="zoom:33%;" />



#### 1.1.2 机器如何学习

可以按照不同的算法训练出不同的模型，我们需要从中挑选**更优**的模型。可以通过**模型评估**判断模型的优劣。若评估未通过，则需要**模型调优**。

![image-20221209162840570](https://images.drshw.tech/images/notes/image-20221209162840570.png)

机器学习总体流程：选择算法`f1`、`f2`（最初的算法无预测能力），按照这些算法对数据集进行训练，得到对应算法的模型（具备预测能力），通过大量测试样本对各个模型进行评估，最后筛选出最优的模型：

![image-20221209163807688](https://images.drshw.tech/images/notes/image-20221209163807688.png)

### 1.2 机器学习的分类

#### 1.2.1 机器学习的分类

机器学习算法非常多，按照算法原理及模型训练方式不同，可以将众多机器学习算法划分为三大类

+ 监督学习：Supervised Learning

+ 非监督学习：Unsupervised Learning

+ 强化学习：Reinforcement Learning

![image-20221209163933475](https://images.drshw.tech/images/notes/image-20221209163933475.png)

#### 1.2.2 监督学习

监督学习，就是先利用**有标签的训练数据**学习得到一个模型，然后使用这个模型对新样本进行预测。在本质上，监督学习的目标在于，构建一个由**输入到输出的映射**`f(x)`，该映射用模型来表示。

监督学习算法工作原理：

![image-20221209164206135](https://images.drshw.tech/images/notes/image-20221209164206135.png)

常用监督学习算法：

+ K 近邻（K-Nearest Neighbors, KNN）
+ 线性回归（Linear Regression）
+ 逻辑回归（Logistic Regression）
+ 支持向量机（Support Vector Machine，SVM）
+ 朴素贝叶斯（Naive Bayes）
+ 决策树（Decision Tree）
+ 随机森林（Random Forests）
+ 神经网络（Neural Network）



#### 1.2.3 无监督学习

与监督学习相比，无监督学习更像是**自学**；所给的数据集是**未加标签的数据**，没有类别信息，也没有给定的目标值，需要算法自动发现或挖掘出数据之间的关系。

无监督学习算法工作原理：

![image-20221209164220254](https://images.drshw.tech/images/notes/image-20221209164220254.png)

常见无监督学习算法：

+ K均值聚类（K-Means Clustering）
+ 基于密度的聚类方法（DBSCAN）
+ 主成分分析（PCA）

#### 1.2.4 强化学习

强化学习不同于监督学习和非监督学习，在强化学习中**没有原始数据输入**让算法来学习。强化学习面对的是一个不断变化的状态空间，要解决的是一个决策链问题。

![image-20221209164255355](https://images.drshw.tech/images/notes/image-20221209164255355.png)

常见强化学习算法：

+ Q-Learning
+ SARSA
+ DQN
+ DDPG

### 1.3 机器学习的实际应用场景

#### 1.3.1 分类问题应用

**分类问题**就是构造一个分类器（Classifier），可以对数据样本的类别进行预测，分类器可以理解为一个函数：`y = f(x)`，其中是自变量（特征变量）， `y`是因变量（目标变量），而且`y`的取值不是数值而是一个类别标签，当我们知道了`x`的值之后，就可以根据`y = f(x)`来预测`y`的值。

分类问题属于监督学习的范畴。

下图中，黑色的直线即为分类器，`X`、`Y`都为特征变量，目标变量为类别（即离散点的颜色）

![image-20221209164335674](https://images.drshw.tech/images/notes/image-20221209164335674.png)

应用：

![image-20221209164411035](https://images.drshw.tech/images/notes/image-20221209164411035.png)

#### 1.3.2 回归问题应用

**回归问题**和分类问题非常像，它们都属于**监督学习**的范畴；分类问题要构建的是分类器（Classifier），而回归问题需要构建的就是一个回归器（Regressor）。回归器也是一个函数：`y = f(x)`，其中`x`是自变量，`y`是因变量，与分类问题不同的是，`y`的取值是数值而不是类别。当知道了`x`的值之后，就可以通过`y = f(x)`来预测`y`的值：

<img src="https://images.drshw.tech/images/notes/image-20221209164945376.png" alt="image-20221209164945376" style="zoom:80%;" />

常见应用：

+ 销量预测：根据商品的相关特征来预测商品的销量股票；
+ 价格预测：根据股票的历史变化趋势，预测未来的走势；
+ 库存量预测：根据商品的历史销量及当前库存量预测需要进货量。

![image-20221209165148888](https://images.drshw.tech/images/notes/image-20221209165148888.png)

#### 1.3.3 聚类问题应用

“物以类聚，人以群分”，这就是聚类，它的目的就是要把相似的数据聚在一起。例如通信运营商可以对手机用户的通话行为进行聚类，把喜欢上网的聚为一类，喜欢夜间打电话的聚为另外一类。

聚类问题属于非监督学习的范畴。

<img src="https://images.drshw.tech/images/notes/image-20221209165347018.png" alt="image-20221209165347018" style="zoom:80%;" />

常见应用：

+ 用户分群：企业对用户的消费行为进行聚类，把用户划分为不同的人群，然后对用户进行差异化的服务；
+ 相似文档归类：对大量的文档进行聚类分析后，把文档分为若千个不同的类。

<img src="https://images.drshw.tech/images/notes/image-20221209165423159.png" alt="image-20221209165423159" style="zoom:80%;" />

聚类中的“类”与分类中的“类”有何区别?

+ 分类问题的“类”就是训练样本标签，这个标签是**训练模型之前**需要事先标记好的，分类算法目标是建立一个对标签进行预测的模型；
+ 聚类的“类”，是聚类算法需要对数据进行**学习之后**才能得到的结果，在训练模型之前我们是不知道样本的类别标签。

#### 1.3.4 关联规则（Association Rule）应用

关联规则分析也称为购物篮分析，可以从交易型数据中发现频繁关联出现的`item`（商品）。早期是为了发现超市销数据中不同商品的关联关系，帮助超市或商家了解客户的购买模式和习惯，以便于制定更好的销售计划：

例如：计算出牛奶、面包、纸巾三者的关联度很高，可将其摆在一个货架上：

![image-20221209165551836](https://images.drshw.tech/images/notes/image-20221209165551836.png)

这里的`item`在不同的场景可以代表不同的物品。

一些名词的概念：

+ 项集 `Itemset`：

  + 1个或者多个`item`的集合，例如：`{Milk, Bread, Diaper}`；

  + `k`项集：包含`k`个`item`的项集；

+ 支持数量 `Support Count`：
  + 项集中的item在交易数据中同时出现 (购买) 的次数；
  + `σ({fMilk, Bread, Diaper}) = 2`；

+ 支持度 `Support`：
  + 支持数量/总交易数量；
  + `support({Milk, Bread, Diaperl) = 2/5`；

+ 频繁项集 `Frequent ltemset`：
  + 支持度`support`**大于最小支持度**（`minsup`）的项集合。

<img src="https://images.drshw.tech/images/notes/image-20221209170011913.png" alt="image-20221209170011913" style="zoom:80%;" />

+ 关联规则 Association Rule
  + `X → Y`，`X`和`Y`是项集（1项或者多项）
  + 例如：`{Milk, Diaper} → {Beer}`

+ 关联规则的评估指标

  + 支持度 `Support`：`P(X ∩ Y) = N(X ∩ Y) / N`

  + 可信度 `Confidence`：`P(Y | X) = P(X ∩ Y) / P(X) = N(X ∩ Y) / N(X)`

  + 例如：

    <img src="https://images.drshw.tech/images/notes/image-20221209170651224.png" alt="image-20221209170651224" style="zoom:80%;" /> 

    

#### 1.3.5 序列预测应用

序列预测问题主要包含以下三大类：

+ 时间序列预测：根据历史天气情况预测未来一天或几天天气情况：

  <img src="https://images.drshw.tech/images/notes/image-20221209212852329.png" alt="image-20221209212852329" style="zoom:80%;" />

+ 序列型关联规则：例如先看了速度与激情 1，接下来看速度与激情 2 的可能性比较大等；

+ 语言模型：分词，语音识别，机器翻译等都属于序列问题：

  ![image-20221209212921024](https://images.drshw.tech/images/notes/image-20221209212921024.png)

序列问题既可以是**非监督学习**的方法，也可以转换为回归，分类等**监督学习**的问题。

#### 1.3.6 异常值检测应用

异常检测就是检测样本取值是否显著的偏离常规，从中发现有意义的**孤立点**和**异常值** 。**监督学习**和**非监督学习**都可以
应用于异常检测问题：

如下图，`N1`、`N2`、`O3`均是正常的样本；而`O1`、`O2`则是偏离常规的孤立点，需要被剔除：

<img src="https://images.drshw.tech/images/notes/image-20221209213047497.png" alt="image-20221209213047497" style="zoom:80%;" />

常见的异常检测问题有：

+ 信用卡异常消费检测（欺诈检测）
+ 网络安全检测
+ 不合格产品检测

### 1.4 机器学习建模流程

机器学习开发流程：

<img src="https://images.drshw.tech/images/notes/image-20221209213316220.png" alt="image-20221209213316220" style="zoom:80%;" />

该开发流程基于的前提是：**算法设置及模型参数选择均正确**，若算法有误或模型参数选择有误还应当重新调整。

## 第二章 深度学习

### 2.1 深度学习概述

#### 2.1.1 AI & ML & DL简介与深度学习基本概念

![image-20221209213857674](https://images.drshw.tech/images/notes/image-20221209213857674.png)

+ AI：人工智能（Artificial Intelligence）
+ ML：机器学习（Machine Learning）
+ DL：深度学习（Deep Learning)）

**深度学习**是用于建立、模拟人脑进行分析学习的神经网络，并模仿人脑的机制来解释数据的一种机器学习技术。它的基本特点是试图模仿大脑的**神经元**之间传递，处理信息的模式，如下图：

![image-20221209214001491](https://images.drshw.tech/images/notes/image-20221209214001491.png)

神经网络结构分为三层：输入层、隐藏层（数量无限制）、输出层。每个圆圈代表一个神经元，每条线代表一个训练参数。输出层的神经元个数由**任务目标**决定。

例如，识别图片的工作流程：

![image-20221209225011373](https://images.drshw.tech/images/notes/image-20221209225011373.png)

#### 1.2.2 深度学习与机器学习

+ 机器学习：需要数据采集、数据标注、一列数据预处理及特征工程之后才能进行模型训练；

+ 深度学习：只需做简单的数据采集、数据标注及预处理，便可进行模型训练；

<img src="https://images.drshw.tech/images/notes/image-20221209214519084.png" alt="image-20221209214519084" style="zoom:80%;" />

#### 1.2.3 深度学习主要应用

**深度学习**最显著的应用是**计算机视觉（Computer vision）**和**自然语言处理（NLP）**领域：

+ 计算机视觉（CNN）
  + 图像识别：图像聚类、分类;例如人脸识别，车牌识别，OCR等；
  + 以图搜图，图像分割；
  + 目标检测：如自动驾驶的行人检测，安防系统的异常人群检测；
+ 自然语言处理（RNN）
  + 语音识别，**语音合成**；
  + **知识图谱**，机器翻译，人机对话，机器写作；
  + 文本分类，情感分析，问答系统；

#### 1.2.4 生物神经网络与人工神经网络

生物神经网络：

+ 人的大脑由大约800亿个神经元组成每个神经元通过突触与其他神经元连接，接受这些神经元传来的电信号和化学信号，对信号汇总处理之后，输出到其他神经元；
+ 大脑通过神经元之间的协作来完成它的功能，神经元之间的连接关系是在进化过程以及生长发育、长期的学习、对外界环境的刺激反馈中建立起来的。 

![image-20221209214627702](https://images.drshw.tech/images/notes/image-20221209214627702.png)

如上图，信号通过神经元A的轴突，传递给神经元B的树突。

人工神经网络：

人工神经网络是对生物神经网络的模拟。它由多个相互连接的神经元构成，这些神经元从其它相连的神经元接受输入数据，通过计算产生输出数据，这些输出数据会送入其他神经元继续处理。

人工神经网络结构如下：

![image-20221209214920871](https://images.drshw.tech/images/notes/image-20221209214920871.png)

### 2.2 深度学习发展历史

历史发展简图：

<img src="https://images.drshw.tech/images/notes/image-20221209215047377.png" alt="image-20221209215047377" style="zoom:80%;" />

#### 2.2.1 1958 年: 感知机的兴起

1958 年，弗兰克·罗森布拉特发明了感知机，这是一种非常简单的机器模型，后来成为当今智能机器的核心和起源。感知机是一个非常简单的二元分类器，可以确定给定的输入图像是否属于给定的类。

为了实现这一点，它使用了单位阶跃激活函数。使用单位阶跃激活函数，如果输入大于0，则输出为 1，否则为0。下图是感知机的算法：

<img src="https://images.drshw.tech/images/notes/image-20221209215053094.png" alt="image-20221209215053094" style="zoom:67%;" />

#### 2.2.2 1982-1986:循环神经网络（RNN）

在多层感知机显示出解决图像识别问题的潜力之后，人们开始思考如何对文本等序列数据进行建模。此时便产生了循环神经网络，这是一类旨在处序列的神经网络。与多层感知机（MLP）等前馈网络不同，RNN有一个内部反馈回路，负责记住每个时间步长的信息状态。

前馈网络与循环神经网络：

<img src="https://images.drshw.tech/images/notes/image-20221209215158679.png" alt="image-20221209215158679" style="zoom: 67%;" />

第一种 RNN 单元在 **1982 年到 1986年之间**被发现，但它并没有引起人们的注意，因为简单的RNN单元在用于长序列时会受到很大影响，主要是存在记忆力短和梯度不稳定的问题。

#### 1998: LeNet-5，第一个CNN架构
LeNet-5是最早的卷积网络架构之一，于1998年用于文档识别。LeNet-5由3个部分组成：2个卷积层、2个子采样或池化层和3个全连接层。

卷积层中没有激活函数。

<img src="https://images.drshw.tech/images/notes/image-20221209215233528.png" alt="image-20221209215233528" style="zoom:67%;" />

LeNet-5在当时确实是一个有影响力的研究，但它（常规的卷积网络）直到20年后才受到关注。

#### 2.2.3 1998: 长短期记忆 (LSTM)

由于梯度不稳定的问题，简单RNN单元无法处理长序列问题。LSTM 是可用于处理长序列的RNN版本。LSTM基本上是RNN单元的极端情况。LSTM 单元的一个特殊设计差异是它有一个门机制，这是它可以控制多个时间步长的信息流的基础。

<img src="https://images.drshw.tech/images/notes/image-20221209215254763.png" alt="image-20221209215254763" style="zoom:50%;" />

LSTM使用门来控制从当前时间步长到下一个时间步长的信息流，有以下4种方式：

+ 输入门识别输入序列；
+ 遗忘门去掉输入序列中包含的所有不相关信息，并将相关信息存储在长期记忆中；
+ LTSM单元更新“更新单元“的状态值；
+ 输出门控制必须发送到下一个时间步长的信息；

LSTM处理长序列的能力使其成为适合各种序列任务的神经网络架构，例如**文本分类、情感分析、语音识别、图像标题生成和机器翻译**。LSTM是一种强大的架构，但它的计算成本很高。2014年推出的GRU（Gated Recurrent Unit）可以解决这个问题。与LSTM相比，GRU的参数更少，效果也很好。

#### 2.2.4 2014 年 : 深度生成网络

生成网络用于从训练数据中生成或合成新的数据样本，例如图像和音乐，下图简要说明了GAN 的模型架构：

<img src="https://images.drshw.tech/images/notes/image-20221209215314250.png" alt="image-20221209215314250" style="zoom:67%;" />

+ GAN一直是深度学习社区中最热门的研究之一，该社区以生成伪造的图像和 Deepfake 视频而闻名；
+ 一些AI作画就是基于该技术实现的；
+ GAN 资源的完整列表: [https://github.com/nashory/gans-awesome-applications](https://github.com/nashory/gans-awesome-applications)。

#### 2.2.5 2017 年: Transformers 和注意力机制

一种完全基于注意力机制的新神经网络架构横空出世。并且 NLP 再次受到启发，在随后的几年，注意力机制继续主导其他方向（最显著的是视觉）。该架构被称为 Transformer：

<img src="https://images.drshw.tech/images/notes/image-20221209215513120.png" alt="image-20221209215513120" style="zoom: 67%;" />

Transformer 彻底改变了 NLP，目前它也在改变着计算机视觉领域。在 NLP 领域，它被用于机器翻译、文本摘要、语音识别、文本补全、文档搜索等。

### 2.3 深度学习的主要应用

#### 2.3.1 语音处理

+ 语音识别：通过一段语音识别出语音对应的文字；

+ 语音生成：通过机器根据文字生成特定风格的音频；
  + 高德地图高航语音包：小团团，林志玲，于谦，李佳琦；
  + 抖音视频文字自动解说；

+ 语音唤醒（voice trigger, VT）；

+ 语音增强（Speech Enhancement）；

+ 语音信号被各种各样的噪声（包括语音）干扰甚至淹没后，从含噪声的语音信号中提取出纯净语音的过程。

<img src="https://images.drshw.tech/images/notes/image-20221209215532721.png" alt="image-20221209215532721" style="zoom:50%;" />

#### 2.3.2 图像处理

+ 图像分类

+ 目标检测/目标分割

  <img src="https://images.drshw.tech/images/notes/image-20221209215557572.png" alt="image-20221209215557572" style="zoom: 67%;" />

+ 图像生成

  <img src="https://images.drshw.tech/images/notes/image-20221209215640728.png" alt="image-20221209215640728" style="zoom: 50%;" />

+ 图像修复

  <img src="https://images.drshw.tech/images/notes/image-20221209215626020.png" alt="image-20221209215626020" style="zoom: 50%;" />

#### 2.3.3 NLP自然语言处理

+ 文本自动分词、句法分析，语法纠错，关键词提取：

  <img src="https://images.drshw.tech/images/notes/image-20221209215816008.png" alt="image-20221209215816008" style="zoom:50%;" />

+ 文本分类/聚类，文本自动摘要，信息检索（ES, Solr）：

  <img src="https://images.drshw.tech/images/notes/image-20221209215833486.png" alt="image-20221209215833486" style="zoom: 67%;" />

+ 知识图谱，机器翻译，人机对话，机器写作：

  <img src="https://images.drshw.tech/images/notes/image-20221209215847841.png" alt="image-20221209215847841" style="zoom:50%;" />

+ 信息抽取，情感分析，问答系统。

## 第三章 感知机与神经网络

### 3.1 神经元数学模型

#### 3.1.1 人工神经元模型基本原理

人工神经元模型：多个输入和对应的权重做内积运算（inner product / dot product / scalarproduct） , 通过激活函数输
出结果。信息在神经元之间传递，例如：

+ 输入：`x1`、`x2`、`x3`；

+ 输出：：函数![](https://images.drshw.tech/images/notes/image-20221209220832203.png)，其中`w`和`b`是参数：

  ![image-20221209220901108](https://images.drshw.tech/images/notes/image-20221209220901108.png)

+ 注意：函数`g`被称为**激活函数**；常用激活函数有Sigmoid（逻辑回归函数）和tanh（双曲正切函数）：

  ![image-20221209220954376](https://images.drshw.tech/images/notes/image-20221209220954376.png)

<img src="https://images.drshw.tech/images/notes/image-20221209221033275.png" alt="image-20221209221033275" style="zoom: 67%;" />

#### 3.1.2 内积运算

对于内积运算，我们已经很熟悉了。它的公式与处理机逻辑如下：

<img src="https://images.drshw.tech/images/notes/image-20221209221223675.png" alt="image-20221209221223675" style="zoom:67%;" />

说明：`a = σ(Σai * wi + b), 1 ≤ i ≤ k`。

#### 3.1.3 激活函数

激活函数工作原理示例：

<img src="https://images.drshw.tech/images/notes/image-20221209221257345.png" alt="image-20221209221257345" style="zoom:67%;" />

说明：`res = σ(2*1 + (-1)*(-2) + 1*(-1)) + 1) = 0.98`。

### 3.2 感知机的概念

#### 3.2.1 单层感知机

单层感知机的结构如下：

<img src="https://images.drshw.tech/images/notes/image-20221209221753678.png" alt="image-20221209221753678" style="zoom:50%;" />

应用案例：预测客户是否会离开。

输入神经元：

+ `X1`为客户投诉数量；
+ `X2`为客户订单总金额；
+ `X3`为客户支持总小时数；
+ `Xn`为客户公司总资本。

中间神经元：

+ `m`中间神经元为数学计算，公式为<img src="https://images.drshw.tech/images/notes/image-20221209222031879.png" alt="image-20221209222031879" style="zoom:80%;" />。

#### 3.2.2 多层感知机

多层感知机（Multilayer Perceptron，MLP）是一类前馈人工神经网络。 MLP至少包含三层节点。除了输入节点，每
个节点都是一个使用非线性激活函数的神经元。MLP使用反向传播算法进行训练。MLP的多层和非线性激活将MLP与
线性感知器区分开来，它可以区分非线性可分的数据：

![image-20221209222253401](https://images.drshw.tech/images/notes/image-20221209222253401.png)

上图中的隐藏层层数为1，有多个隐藏层当然也是可以的，例如：

<img src="https://images.drshw.tech/images/notes/image-20221209222350356.png" alt="image-20221209222350356" style="zoom: 80%;" />

<img src="https://images.drshw.tech/images/notes/image-20221209222400468.png" alt="image-20221209222400468" style="zoom: 67%;" />

### 3.3 激活函数分类与必要性

#### 3.3.1 逻辑回归函数 Sigmoid

Sigmoid 是常用的非线性的激活函数，它的数学形式：<img src="https://images.drshw.tech/images/notes/image-20221209222456697.png" alt="image-20221209222456697" style="zoom: 80%;" />。

Sigmoid的几何图像如下：

![image-20221209222559745](https://images.drshw.tech/images/notes/image-20221209222559745.png)

特点： 它能够把输入的连续实值变换为**0和1之间**的输出，特别的，如果是非常大的负数，那么输出就是0；如果是非常大的正数，输出就是1。

缺点：在深度神经网络中梯度反向传递时导致梯度爆炸和梯度消失，其中梯度爆炸发生的概率非常小，而梯度消失发生的概率比较大。

#### 3.3.2 双曲正切函数 tanh

tanh 函数解析式：<img src="https://images.drshw.tech/images/notes/image-20221209222738542.png" alt="image-20221209222738542" style="zoom:80%;" />。

tanh 函数及其导数的几何图像如下图：

![image-20221209222712740](https://images.drshw.tech/images/notes/image-20221209222712740.png)

#### 3.3.3 斜坡函数 ReLu

Relu 函数的解析式：<img src="https://images.drshw.tech/images/notes/image-20221209222842216.png" alt="image-20221209222842216" style="zoom:80%;" />。

ReLu 函数及其导数的几何图像如下图：

![image-20221209222756250](https://images.drshw.tech/images/notes/image-20221209222756250.png)

#### 3.3.4 激活函数的必要性

假设下图中的神经网络没有激活函数：

<img src="https://images.drshw.tech/images/notes/image-20221209223242379.png" alt="image-20221209223242379" style="zoom:95%;" />

于是，得到如下关系：

<img src="https://images.drshw.tech/images/notes/image-20221209223328007.png" alt="image-20221209223328007" style="zoom:80%;" />

于是该神经网络可以优化为：

<img src="https://images.drshw.tech/images/notes/image-20221209223447517.png" alt="image-20221209223447517" style="zoom:95%;" />

即将隐藏层删去，输入输出逻辑均不变：

<img src="https://images.drshw.tech/images/notes/image-20221209223532323.png" alt="image-20221209223532323" style="zoom:80%;" />

这样一来，所有的模型训练结果都是确定的，是一种线性关系，而预测分析的大部分情况都是非线性的。

激活函数设置的目的，即**改变输入和输出之间的线性关系**，一旦引入了激活函数，`z4`将不会如此“确定”。

### 3.4 神经网络参数求解

神经网络的求解目标`W`的算法，分为信号“正向传播(FP)”求损失，“反向传播(BP)”回传误差；根据误差值修改每层的权重，继续迭代。

基本流程如下：

![image-20221209224033341](https://images.drshw.tech/images/notes/image-20221209224033341.png)

### 3.5 神经网络的深度与广度

思考一个问题，为何我们讨论的更多的是**深度**神经网络，而非**广度**神经网络呢？

![image-20221209224347884](https://images.drshw.tech/images/notes/image-20221209224347884.png)

这是由于存在以下的实验结论：

![image-20221209224446860](https://images.drshw.tech/images/notes/image-20221209224446860.png)

可以看出，增加广度要比增加深度带来的误差变化更多，所以神经网络要尽可能往**深度**拓展。

举例，一个神经网络模型如下：

![image-20221209224805284](https://images.drshw.tech/images/notes/image-20221209224805284.png)

需要大量样本才能得到不错的模型。

将其拓广一层，有些神经元负责识别是男孩还是女孩，有些负责识别头发的长短：

<img src="https://images.drshw.tech/images/notes/image-20221209224830810.png" alt="image-20221209224830810" style="zoom: 67%;" />

这样一来，只需要更少的样本就可以得到不错的模型了。

## 第四章 卷积神经网络CNN

图片被识别成什么不仅仅取决于图片本身，还取决于图片是如何被观察的：

<img src="https://images.drshw.tech/images/notes/image-20221209225936020.png" alt="image-20221209225936020" style="zoom:50%;" />

为了确定我们识别的目标，需要引入卷积神经网络这项技术。

### 4.1 视觉感知和图像表达

#### 4.1.1 图像数据的存储方式

图像识别是从大量的`(x, y)`数据中寻找人类的视觉关联方式 ，并再次应用。`x`是输入，表示所看到的东西。`y`是输
出，表示该东西是什么；

在自然界中，`x`是物体的反光，那么在计算机中，图像又是如何被表达和存储的呢？

+ 图像在计算机中是一堆按顺序排列的数字，数值为0到255；0表示最暗，255表示最亮：

  ![image-20221209230247654](https://images.drshw.tech/images/notes/image-20221209230247654.png)

+ 更普遍的图片表达方式是RGB颜色模型，即红（Red）、绿（Green）、蓝（Blue）三原色的色光以不同的比例相加，以产生多种多样的色光；

+ 在电脑中，一张图片是数字构成的“长方体”。可用 宽width, 高height, 深depth 来描述，图像识别的输入`x`是`shape`为`(width, height, depth)`的三维张量：

  <img src="https://images.drshw.tech/images/notes/image-20221209230234972.png" alt="image-20221209230234972" style="zoom:67%;" />

#### 4.1.2 画面不变性

在决定如何处理“数字长方体”之前，需要清楚所建立的网络拥有什么样的特点。 我们知道一个物体不管在画面左侧还是右侧，都会被识别为同一物体，这一特点就是不变性（invariance），如下图所示：

<img src="https://images.drshw.tech/images/notes/image-20221209230351114.png" alt="image-20221209230351114" style="zoom:80%;" />

为了理解卷积神经网络对这些不变性特点的贡献，我们将用不具备这些不变性特点的前馈神经网络（DNN）来进行比较。

### 4.2 卷积神经网络原理

#### 4.2.1 卷积神经网络的作用

假设：在宽长为4x4的图片中识别是否有下图所示的“横折”：

![image-20221209230605137](https://images.drshw.tech/images/notes/image-20221209230605137.png)

方便起见，我们用depth只有1的灰度图来举例。 图中，黄色圆点表示值为0的像素，深色圆点表示值为1的像素。 我们知道不管这个横折在图片中的什么位置，都会被认为是相同的横折。

若训练前馈神经网络来完成该任务，那么表达图像的三维张量将会被摊平成一个向量，作为网络的输入，即`(width, height, depth)`为`(4, 4, 1)`的图片会被展成维度为16的向量作为网络的输入层。再经过几层不同节点个数的隐藏层，最终输出两个节点，分别表示“有横折的概率”和“没有横折的概率”，如下图所示：

<img src="https://images.drshw.tech/images/notes/image-20221209230712438.png" alt="image-20221209230712438" style="zoom: 67%;" />

对于某些特殊情况，这种方式会失效：

![image-20221209230732397](https://images.drshw.tech/images/notes/image-20221209230732397.png)

解决办法是用大量物体位于不同位置的数据训练，同时增加网络的隐藏层个数从而扩大网络学习这些变体的能力。然而这样做效率很低，因为我们知道在左侧的“横折”也好，还是在右侧的“横折”也罢，大家都是“横折”，为什么相同的东西在位置变了之后要重新学习？有没有什么方法可以将中间所学到的规律也运用在其他的位置？

换句话说就是：**让不同位置用相同的权重**，这也是卷积神经网络的作用。

#### 4.2.2 卷积神经网络组成

卷积神经网络（CNN）就是让**权重在不同位置共享的神经网络**，由以下部分组成：

+ 卷积核
+ Zero Padding
+ 步长
+ 多通道卷积
+ 多卷积核
+ 激励函数
+ 池化Pooling
+ 卷积网络结构

##### 卷积核

在卷积神经网络中，我们先选择一个局部区域，用这个局部区域去扫描整张图片。局部区域所圈起来的所有节点会被连接到下一层的一个节点上：

![image-20221209232536381](https://images.drshw.tech/images/notes/image-20221209232536381.png)

这个带有连接强弱的红色方框就叫做`filter`或`kernel`或`feature detector`，就是我们所说的卷积核。

filter 的范围叫做 `filter size`。

##### 卷积核局部连接

第二层的节点0的数值就是局部区域的线性组合，即被圈中节点的数值乘以对应的权重后相加。 用`x`表示输入值，`y`表示输出值，用图中标注数字表示角标，则下面列出了两种计算编号为0的输出值`y0`的表达式：

<img src="https://images.drshw.tech/images/notes/image-20221209232710996.png" alt="image-20221209232710996" style="zoom:80%;" />

![image-20221209232632006](https://images.drshw.tech/images/notes/image-20221209232632006.png)

注：在局部区域的线性组合后，也会和前馈神经网络一样，加上一个偏移量。

这样做相当于将一张图片拆分成一个个小区域，提取每一个小区域中图片的特征，例如：

<img src="https://images.drshw.tech/images/notes/image-20221209232839471.png" alt="image-20221209232839471" style="zoom: 67%;" />

基于人脑的图片识别过程，我们可以认为图像的空间联系也是局部的像素联系比较紧密，而较远的像素相关性比较弱，所以每个神经元没有必要对全局图像进行感知，只要对局部进行感知，而在更高层次对局部的信息进行综合操作得出全局信息。

<img src="https://images.drshw.tech/images/notes/image-20221209232912201.png" alt="image-20221209232912201" style="zoom:80%;" />

##### 卷积核权重共享

当`filter`扫到其他位置计算输出节点`yi`时，`w1`、`w2`、`w3`、`w4`包括`b0`都是共用的。

下图展示了当filter扫过不同区域时，节点的链接方式：

![image-20221209233227452](https://images.drshw.tech/images/notes/image-20221209233227452.png)

动态图的最后一帧则显示了所有连接。 可以注意到，每个输出节点并非像前馈神经网络中那样与全部的输入节点连接，而是部分连接。 这也就是为什么大家也叫前馈神经网络（feedforwardneural network）为fully-connected neural network。 图中显示的是一步一步的移动`filter`来扫描全图，一次移动多少叫做`stride`。

##### 卷积核输出表达

如下图，输入（绿色）的每九个节点连接到输出（粉红色）的一个节点上的：

![image-20221209233348800](https://images.drshw.tech/images/notes/image-20221209233348800.png)

经过一个feature detector计算后得到的粉红色区域也叫做一个“Convolved Feature” 或 “Feature Map”：

![image-20221209233414504](https://images.drshw.tech/images/notes/image-20221209233414504.png)

##### 特征提取器

一张图片经过不同的卷积核可以提取到不同的部分：

<img src="https://images.drshw.tech/images/notes/image-20221209233621810.png" alt="image-20221209233621810" style="zoom:50%;" />

提取原理与流程（左边可看作图片，中间看作卷积和，右边看作输出特征）：

<img src="https://images.drshw.tech/images/notes/image-20221209233747366.png" alt="image-20221209233747366" style="zoom: 25%;" />

按照上述方式分别计算，填满右侧格子即可：

<img src="https://images.drshw.tech/images/notes/image-20221209233805074.png" alt="image-20221209233805074" style="zoom:25%;" />

![image-20221209234155907](https://images.drshw.tech/images/notes/image-20221209234155907.png)

##### 图像尺度变小：Zero Padding

5x5的图片被3x3的filter卷积后变成了3x3的图片，每次卷积后都会小一圈的话，经过若干层后岂不是变的越来越小？

![image-20221209234302159](https://images.drshw.tech/images/notes/image-20221209234302159.png)

**Zero Padding**就可以在这时帮助控制Feature Map的输出尺寸（对Feature Map进行填充），避免了边缘信息被一步步舍弃的问题。

例如：下面4x4的图片在边缘Zero Padding一圈后，再用3x3的filter卷积后，得到的Feature Map尺寸依然是4x4不变：

![image-20221209234349632](https://images.drshw.tech/images/notes/image-20221209234349632.png)

##### 步长和尺寸计算

填充过程如下：

<img src="https://images.drshw.tech/images/notes/image-20221209235048752.png" alt="image-20221209235048752" style="zoom: 90%;" />

填充后的尺寸大小为<img src="https://images.drshw.tech/images/notes/image-20221209235129108.png" alt="image-20221209235129108" style="zoom:67%;" />，其中：

+ `n`为原始图片宽度；
+ `p`为填充边缘宽度；
+ `f`为卷积核宽度；
+ `s`为步长；

对于上图的填充过程而言，`n = 4, p = 1, f = 3, s = 1`，故填充后为大小`4 * 4`。

![image-20221209234547561](https://images.drshw.tech/images/notes/image-20221209234547561.png)

##### `numpy` 实现单通道卷积

```python
def numpy_conv(inputs, _filter, _result, padding=VALID)
	H,W = inputs.shape
	filter_size = _filter.shape[0]
	# default np.floor
	filter_center = int(filter_size / 2.0)
	filter_center_ceil = int(np.ceil(filter_size / 2.0))
	# 这里先定义一个和输入一样的大空间，但是周围一圈后面会截掉
	result = np.zeros(_result.shape)#更新下新输入，SAME模式下，会改变HW
	H, W = inputs.shape
	# print("new size", H, W)
	# 卷积核通过输入的每块区域，stride=1，注意输出坐标起始位置
	for r in range(0, H - filter_size + 1): 
        for c in range(0,w - filter_size + 1):
			# 卷积核大小的输入区域
			cur_input = inputs[r: r + filter_size, c: c + filter_size]
			# 与核进行乘法计算
			cur_output = cur_input * _filter
 			# 再把所有值求和
			conv_sum = np.sum(cur_output)
 			# 当前点输出值
			result[r, c] = conv_sum
	return result
```



